import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime

def parse_hacker_news():
    """–ü–∞—Ä—Å–∏—Ç –Ω–æ–≤–æ—Å—Ç–∏ —Å Hacker News"""
    url = "https://news.ycombinator.com/"
    
    try:
        response = requests.get(url)
        response.raise_for_status()
    except:
        print("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
        return []

    soup = BeautifulSoup(response.text, 'html.parser')
    news_list = []
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
    titles = soup.find_all('span', class_='titleline')
    
    for i, title in enumerate(titles, 1):
        try:
            title_link = title.find('a')
            news_title = title_link.text.strip()
            news_url = title_link.get('href', '')
            
            # –ò—â–µ–º –º–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            row = title.find_parent('tr')
            subtext = row.find_next_sibling('tr').find('td', class_='subtext')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            comments = 0
            if subtext:
                comments_elem = subtext.find_all('a')[-1]
                if comments_elem and 'comment' in comments_elem.text:
                    comments_text = comments_elem.text
                    for word in comments_text.split():
                        if word.isdigit():
                            comments = int(word)
                            break
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ—Å—Ç—å
            news_list.append({
                'id': i,
                'title': news_title,
                'url': news_url if news_url.startswith('http') else f'https://news.ycombinator.com/{news_url}',
                'comments': comments
            })
            
        except:
            continue
    
    return news_list

def save_to_json(news_data, filename='data.json'):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–∞–π–ª"""
    data = {
        'last_updated': datetime.now().isoformat(),
        'source': 'https://news.ycombinator.com/',
        'news_count': len(news_data),
        'news': news_data
    }
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

def print_news_to_console(news_data):
    """–í—ã–≤–æ–¥–∏—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ –∫–æ–Ω—Å–æ–ª—å"""
    print("\n–ù–æ–≤–æ—Å—Ç–∏ —Å Hacker News:")
    print("=" * 50)
    
    for news in news_data:
        title = news['title']
        if len(title) > 50:
            title = title[:47] + "..."
        print(f"{news['id']}. Title: {title}; Comments: {news['comments']};")
    
    print(f"\n–í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(news_data)}")

def generate_html(news_data, filename='index.html'):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å —Ç–∞–±–ª–∏—Ü–µ–π –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    html_content = f'''<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Hacker News</title>
    <style>
        body {{
            font-family: Arial, sans-serif;
            margin: 20px;
        }}
        h1 {{
            text-align: center;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
        }}
        th {{
            background: #f0f0f0;
            padding: 10px;
            text-align: left;
            border: 1px solid #ccc;
        }}
        td {{
            padding: 8px;
            border: 1px solid #ccc;
        }}
        a {{
            color: #0066cc;
            text-decoration: none;
        }}
        .source-link {{
            text-align: center;
            margin-top: 20px;
        }}
    </style>
</head>
<body>
    <h1>Hacker News Parser</h1>
    <p>–í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(news_data)}</p>
    <p>–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    
    <table>
        <tr>
            <th>#</th>
            <th>–ó–∞–≥–æ–ª–æ–≤–æ–∫</th>
            <th>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏</th>
        </tr>
'''
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
    for news in news_data:
        html_content += f'''
        <tr>
            <td>{news['id']}</td>
            <td><a href="{news['url']}" target="_blank">{news['title']}</a></td>
            <td>{news['comments']}</td>
        </tr>
'''
    
    html_content += f'''
    </table>
    
    <div class="source-link">
        <a href="https://news.ycombinator.com/" target="_blank">
            üîó –ü–æ—Å–µ—Ç–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π Hacker News
        </a>
    </div>
</body>
</html>'''
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"HTML —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ–∑–¥–∞–Ω–∞: {filename}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
    print("–ü–∞—Ä—Å–∏–º Hacker News...")
    
    # –ü–∞—Ä—Å–∏–º –Ω–æ–≤–æ—Å—Ç–∏
    news_data = parse_hacker_news()
    
    if not news_data:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏")
        return
    
    # –í—ã–≤–æ–¥–∏–º –≤ –∫–æ–Ω—Å–æ–ª—å
    print_news_to_console(news_data)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
    save_to_json(news_data)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML
    generate_html(news_data)
    
    print("\n–ó–∞–¥–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ!")
    print("–û—Ç–∫—Ä–æ–π—Ç–µ —Ñ–∞–π–ª index.html –≤ –±—Ä–∞—É–∑–µ—Ä–µ")

if __name__ == "__main__":
    main()